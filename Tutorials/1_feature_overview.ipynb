{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Overview\n",
    "\n",
    "This notebook provides a simple overview of the basic functionality of PySINDy. In addition to demonstrating the basic usage for fitting a SINDy model, we demonstrate several means of customizing the SINDy fitting procedure. These include different forms of input data, different optimization methods, different differentiation methods, and custom feature libraries.\n",
    "\n",
    "An interactive version of this notebook is available on binder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T00:05:47.829870Z",
     "start_time": "2020-03-09T00:05:47.821638Z"
    }
   },
   "source": [
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/dynamicslab/pysindy/v1.7?filepath=examples/1_feature_overview.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T22:20:41.222450Z",
     "start_time": "2020-10-22T22:20:40.308783Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'enzyme' from 'pysindy.utils' (/Users/liampocher/opt/anaconda3/envs/SINDy/lib/python3.10/site-packages/pysindy/utils/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m solve_ivp\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Lasso\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpysindy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m enzyme\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpysindy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lorenz\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpysindy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lorenz_control\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'enzyme' from 'pysindy.utils' (/Users/liampocher/opt/anaconda3/envs/SINDy/lib/python3.10/site-packages/pysindy/utils/__init__.py)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "from pysindy.utils import enzyme\n",
    "from pysindy.utils import lorenz\n",
    "from pysindy.utils import lorenz_control\n",
    "import pysindy as ps\n",
    "\n",
    "# bad code but allows us to ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T22:20:41.226830Z",
     "start_time": "2020-10-22T22:20:41.224162Z"
    }
   },
   "outputs": [],
   "source": [
    "# Seed the random number generators for reproducibility\n",
    "np.random.seed(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A note on solve_ivp vs odeint before we continue\n",
    "The default solver for `solve_ivp` is a Runga-Kutta method (RK45) but this seems to work quite poorly on a number of these examples, likely because they are multi-scale and chaotic. Instead, the LSODA method seems to perform quite well (ironically this is the default for the older `odeint` method). This is a nice reminder that system identification is important to get the right model, but a good integrator is still needed at the end!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize integrator keywords for solve_ivp to replicate the odeint defaults\n",
    "integrator_keywords = {}\n",
    "integrator_keywords['rtol'] = 1e-12\n",
    "integrator_keywords['method'] = 'LSODA'\n",
    "integrator_keywords['atol'] = 1e-12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic usage\n",
    "We will fit a SINDy model to the famous Lorenz system:\n",
    "$$ \\dot{x} = \\sigma (y - x),$$\n",
    "$$ \\dot{y} = x(\\rho - z) - y, $$\n",
    "$$ \\dot{z} = x y - \\beta z. $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T22:20:41.263816Z",
     "start_time": "2020-10-22T22:20:41.240788Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate measurement data\n",
    "dt = .002\n",
    "\n",
    "t_train = np.arange(0, 10, dt)\n",
    "x0_train = [-8, 8, 27]\n",
    "t_train_span = (t_train[0], t_train[-1])\n",
    "x_train = solve_ivp(lorenz, t_train_span, x0_train, \n",
    "                    t_eval=t_train, **integrator_keywords).y.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T22:20:41.306516Z",
     "start_time": "2020-10-22T22:20:41.266947Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate and fit the SINDy model\n",
    "model = ps.SINDy()\n",
    "model.fit(x_train, t=dt)\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess results on a test trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T22:20:41.367601Z",
     "start_time": "2020-10-22T22:20:41.308759Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evolve the Lorenz equations in time using a different initial condition\n",
    "t_test = np.arange(0, 15, dt)\n",
    "x0_test = np.array([8, 7, 15])\n",
    "t_test_span = (t_test[0], t_test[-1])\n",
    "x_test = solve_ivp(lorenz, t_test_span, x0_test, \n",
    "                   t_eval=t_test, **integrator_keywords).y.T  \n",
    "\n",
    "# Compare SINDy-predicted derivatives with finite difference derivatives\n",
    "print('Model score: %f' % model.score(x_test, t=dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict derivatives with learned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T22:20:42.389408Z",
     "start_time": "2020-10-22T22:20:41.370570Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict derivatives using the learned model\n",
    "x_dot_test_predicted = model.predict(x_test)  \n",
    "\n",
    "# Compute derivatives with a finite difference method, for comparison\n",
    "x_dot_test_computed = model.differentiate(x_test, t=dt)\n",
    "\n",
    "fig, axs = plt.subplots(x_test.shape[1], 1, sharex=True, figsize=(7, 9))\n",
    "for i in range(x_test.shape[1]):\n",
    "    axs[i].plot(t_test, x_dot_test_computed[:, i],\n",
    "                'k', label='numerical derivative')\n",
    "    axs[i].plot(t_test, x_dot_test_predicted[:, i],\n",
    "                'r--', label='model prediction')\n",
    "    axs[i].legend()\n",
    "    axs[i].set(xlabel='t', ylabel='$\\dot x_{}$'.format(i))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate forward in time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T22:20:44.604020Z",
     "start_time": "2020-10-22T22:20:42.392280Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evolve the new initial condition in time with the SINDy model\n",
    "x_test_sim = model.simulate(x0_test, t_test)\n",
    "\n",
    "fig, axs = plt.subplots(x_test.shape[1], 1, sharex=True, figsize=(7, 9))\n",
    "for i in range(x_test.shape[1]):\n",
    "    axs[i].plot(t_test, x_test[:, i], 'k', label='true simulation')\n",
    "    axs[i].plot(t_test, x_test_sim[:, i], 'r--', label='model simulation')\n",
    "    axs[i].legend()\n",
    "    axs[i].set(xlabel='t', ylabel='$x_{}$'.format(i))\n",
    "\n",
    "fig = plt.figure(figsize=(10, 4.5))\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "ax1.plot(x_test[:, 0], x_test[:, 1], x_test[:, 2], 'k')\n",
    "ax1.set(xlabel='$x_0$', ylabel='$x_1$',\n",
    "        zlabel='$x_2$', title='true simulation')\n",
    "\n",
    "ax2 = fig.add_subplot(122, projection='3d')\n",
    "ax2.plot(x_test_sim[:, 0], x_test_sim[:, 1], x_test_sim[:, 2], 'r--')\n",
    "ax2.set(xlabel='$x_0$', ylabel='$x_1$',\n",
    "        zlabel='$x_2$', title='model simulation')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different forms of input data\n",
    "\n",
    "Here we explore different types of input data accepted by the the `SINDy` class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single trajectory, pass in collection times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T22:20:44.639616Z",
     "start_time": "2020-10-22T22:20:44.605466Z"
    }
   },
   "outputs": [],
   "source": [
    "model = ps.SINDy()\n",
    "model.fit(x_train, t=t_train)\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single trajectory, set default timestep\n",
    "Since we used a uniform timestep when defining `t_train` we can tell set a default timestep to be used whenever `t` isn't passed in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T22:20:44.698019Z",
     "start_time": "2020-10-22T22:20:44.642128Z"
    }
   },
   "outputs": [],
   "source": [
    "model = ps.SINDy(t_default=dt)\n",
    "model.fit(x_train)\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single trajectory, pass in pre-computed derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T22:20:44.787270Z",
     "start_time": "2020-10-22T22:20:44.700496Z"
    }
   },
   "outputs": [],
   "source": [
    "x_dot_true = np.zeros(x_train.shape)\n",
    "for i in range(t_train.size):\n",
    "    x_dot_true[i] = lorenz(t_train[i], x_train[i])\n",
    "    \n",
    "model = ps.SINDy()\n",
    "model.fit(x_train, t=t_train, x_dot=x_dot_true)\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple trajectories\n",
    "We use the Lorenz equations to evolve multiple different initial conditions forward in time, passing all the trajectories into a single `SINDy` object. Note that `x_train_multi` is a list of 2D numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T22:20:45.314443Z",
     "start_time": "2020-10-22T22:20:44.799439Z"
    }
   },
   "outputs": [],
   "source": [
    "n_trajectories = 20\n",
    "x0s = np.array([36, 48, 41]) * (\n",
    "    np.random.rand(n_trajectories, 3) - 0.5\n",
    ") + np.array([0, 0, 25])\n",
    "x_train_multi = []\n",
    "for i in range(n_trajectories):\n",
    "    x_train_multi.append(solve_ivp(lorenz, t_train_span, x0s[i], \n",
    "                                   t_eval=t_train, **integrator_keywords).y.T)\n",
    "\n",
    "model = ps.SINDy()\n",
    "model.fit(x_train_multi, t=dt, multiple_trajectories=True)\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple trajectories, different lengths of time\n",
    "This example is similar to the previous one, but each trajectory consists of a different number of measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T22:20:45.470710Z",
     "start_time": "2020-10-22T22:20:45.319012Z"
    }
   },
   "outputs": [],
   "source": [
    "n_trajectories = 20\n",
    "x0s = np.array([36, 48, 41]) * (\n",
    "    np.random.rand(n_trajectories, 3) - 0.5\n",
    ") + np.array([0, 0, 25])\n",
    "x_train_multi = []\n",
    "t_train_multi = []\n",
    "for i in range(n_trajectories):\n",
    "    n_samples = np.random.randint(500, 1500)\n",
    "    t = np.arange(0, n_samples * dt, dt)\n",
    "    t_span = (t[0], t[-1])\n",
    "    x_train_multi.append(solve_ivp(lorenz, t_span, x0s[i], \n",
    "                                   t_eval=t, **integrator_keywords).y.T)\n",
    "    t_train_multi.append(t)\n",
    "\n",
    "model = ps.SINDy()\n",
    "model.fit(x_train_multi, t=t_train_multi, multiple_trajectories=True)\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrete time dynamical system (map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T22:20:45.489800Z",
     "start_time": "2020-10-22T22:20:45.473454Z"
    }
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return 3.6 * x * (1 - x)\n",
    "\n",
    "\n",
    "n_steps = 1000\n",
    "eps = 0.001  # Noise level\n",
    "x_train_map = np.zeros((n_steps))\n",
    "x_train_map[0] = 0.5\n",
    "for i in range(1, n_steps):\n",
    "    x_train_map[i] = f(x_train_map[i - 1]) + eps * np.random.randn()\n",
    "model = ps.SINDy(discrete_time=True)\n",
    "model.fit(x_train_map)\n",
    "\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T22:20:45.803257Z",
     "start_time": "2020-10-22T22:20:45.492104Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a dataframe with entries corresponding to measurements and\n",
    "# indexed by the time at which the measurements were taken\n",
    "df = pd.DataFrame(data=x_train, columns=['x', 'y', 'z'], index=t_train)\n",
    "\n",
    "# The column names can be used as feature names\n",
    "model = ps.SINDy(feature_names=df.columns)\n",
    "\n",
    "# Everything needs to be converted to numpy arrays to be passed in\n",
    "model.fit(df.values, t=df.index.values)\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization options\n",
    "In this section we provide examples of different parameters accepted by the built-in sparse regression optimizers `STLSQ`, `SR3`, `ConstrainedSR3`, `SSR`, and `FROLS`. The `Trapping` optimizer is not straightforward to use; please check out Example 8 for some examples. We also show how to use a scikit-learn sparse regressor with PySINDy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STLSQ - change parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T22:20:45.833097Z",
     "start_time": "2020-10-22T22:20:45.805829Z"
    }
   },
   "outputs": [],
   "source": [
    "stlsq_optimizer = ps.STLSQ(threshold=.01, alpha=.5)\n",
    "\n",
    "model = ps.SINDy(optimizer=stlsq_optimizer)\n",
    "model.fit(x_train, t=dt)\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STLSQ - verbose (print out optimization terms at each iteration)\n",
    "The same verbose option is available with all the other optimizers. For optimizers that use the CVXPY\n",
    "package, there is additional boolean flag, verbose_cvxpy, that decides whether or not CVXPY solves will also be verbose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stlsq_optimizer = ps.STLSQ(threshold=.01, alpha=.5, verbose=True)\n",
    "\n",
    "model = ps.SINDy(optimizer=stlsq_optimizer)\n",
    "model.fit(x_train, t=dt)\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SR3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T22:20:45.862190Z",
     "start_time": "2020-10-22T22:20:45.835106Z"
    }
   },
   "outputs": [],
   "source": [
    "sr3_optimizer = ps.SR3(threshold=0.1, thresholder='l1')\n",
    "\n",
    "model = ps.SINDy(optimizer=sr3_optimizer)\n",
    "model.fit(x_train, t=dt)\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SR3 - with trimming\n",
    "`SR3` is capable of automatically trimming outliers from training data. Specifying the parameter `trimming_fraction` tells the method what fraction of samples should be trimmed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T22:20:46.058222Z",
     "start_time": "2020-10-22T22:20:45.865560Z"
    }
   },
   "outputs": [],
   "source": [
    "corrupted_inds = np.random.randint(0, len(x_train), size=len(x_train) // 30)\n",
    "x_train_corrupted = x_train.copy()\n",
    "x_train_corrupted[corrupted_inds] += np.random.standard_normal((len(corrupted_inds), 3))\n",
    "\n",
    "# Without trimming\n",
    "sr3_optimizer = ps.SR3()\n",
    "model = ps.SINDy(optimizer=sr3_optimizer).fit(x_train_corrupted, t=dt, quiet=True)\n",
    "print(\"Without trimming\")\n",
    "model.print()\n",
    "\n",
    "# With trimming\n",
    "sr3_optimizer = ps.SR3(trimming_fraction=0.1)\n",
    "model = ps.SINDy(optimizer=sr3_optimizer).fit(x_train_corrupted, t=dt, quiet=True)\n",
    "print(\"\\nWith trimming\")\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SR3 regularizers \n",
    "The default regularizer with SR3 is the L0 norm, but L1 and L2 are allowed. Note that the pure L2 option is notably less sparse than the other options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr3_optimizer = ps.SR3(threshold=0.1, thresholder='l0')\n",
    "model = ps.SINDy(optimizer=sr3_optimizer).fit(x_train, t=dt, quiet=True)\n",
    "print(\"L0 regularizer: \")\n",
    "model.print()\n",
    "\n",
    "sr3_optimizer = ps.SR3(threshold=0.1, thresholder=\"l1\")\n",
    "model = ps.SINDy(optimizer=sr3_optimizer).fit(x_train, t=dt, quiet=True)\n",
    "print(\"L1 regularizer: \")\n",
    "model.print()\n",
    "\n",
    "sr3_optimizer = ps.SR3(threshold=0.1, thresholder=\"l2\")\n",
    "model = ps.SINDy(optimizer=sr3_optimizer).fit(x_train, t=dt, quiet=True)\n",
    "print(\"L2 regularizer: \")\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SR3 - with variable thresholding\n",
    "`SR3` and its variants (ConstrainedSR3, TrappingSR3, SINDyPI) can use a matrix of thresholds to set different thresholds for different terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without thresholds matrix\n",
    "sr3_optimizer = ps.SR3(threshold=0.1, thresholder='l0')\n",
    "model = ps.SINDy(optimizer=sr3_optimizer).fit(x_train, t=dt)\n",
    "print(\"Threshold = 0.1 for all terms\")\n",
    "model.print()\n",
    "\n",
    "# With thresholds matrix\n",
    "thresholds = 2 * np.ones((10, 3))\n",
    "thresholds[4:, :] = 0.1\n",
    "sr3_optimizer = ps.SR3(thresholder=\"weighted_l0\", thresholds=thresholds)\n",
    "model = ps.SINDy(optimizer=sr3_optimizer).fit(x_train, t=dt)\n",
    "print(\"Threshold = 0.1 for quadratic terms, else threshold = 1\")\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that the x1 term in the second equation correctly gets truncated with these thresholds. \n",
    "\n",
    "### ConstrainedSR3\n",
    "We can impose linear equality and inequality constraints on the coefficients in the `SINDy` model using the `ConstrainedSR3` class. Below we constrain the x0 coefficient in the second equation to be exactly 28 and the x0 and x1 coefficients in the first equations to be negatives of one another. See this [notebook](https://github.com/dynamicslab/pysindy/blob/master/examples/7_plasma_examples.ipynb) for examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T22:20:46.071020Z",
     "start_time": "2020-10-22T22:20:46.062479Z"
    }
   },
   "outputs": [],
   "source": [
    "# Figure out how many library features there will be\n",
    "library = ps.PolynomialLibrary()\n",
    "library.fit(x_train)\n",
    "n_features = library.n_output_features_\n",
    "print(f\"Features ({n_features}):\", library.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T22:20:46.108252Z",
     "start_time": "2020-10-22T22:20:46.073968Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set constraints\n",
    "n_targets = x_train.shape[1]\n",
    "constraint_rhs = np.array([0, 28])\n",
    "\n",
    "# One row per constraint, one column per coefficient\n",
    "constraint_lhs = np.zeros((2, n_targets * n_features))\n",
    "\n",
    "# 1 * (x0 coefficient) + 1 * (x1 coefficient) = 0\n",
    "constraint_lhs[0, 1] = 1\n",
    "constraint_lhs[0, 2] = 1\n",
    "\n",
    "# 1 * (x0 coefficient) = 28\n",
    "constraint_lhs[1, 1 + n_features] = 1\n",
    "\n",
    "optimizer = ps.ConstrainedSR3(constraint_rhs=constraint_rhs, constraint_lhs=constraint_lhs)\n",
    "model = ps.SINDy(optimizer=optimizer, feature_library=library).fit(x_train, t=dt)\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try with normalize columns (doesn't work with constraints!!!)\n",
    "optimizer = ps.ConstrainedSR3(constraint_rhs=constraint_rhs, \n",
    "                              constraint_lhs=constraint_lhs,\n",
    "                              normalize_columns=True, \n",
    "                              threshold=10)\n",
    "model = ps.SINDy(optimizer=optimizer, \n",
    "                 feature_library=library).fit(x_train, t=dt, quiet=True)\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat with inequality constraints\n",
    "eps = 1e-5\n",
    "constraint_rhs = np.array([eps, eps, 28])\n",
    "\n",
    "# One row per constraint, one column per coefficient\n",
    "constraint_lhs = np.zeros((3, n_targets * n_features))\n",
    "\n",
    "# 1 * (x0 coefficient) + 1 * (x1 coefficient) <= eps\n",
    "constraint_lhs[0, 1] = 1\n",
    "constraint_lhs[0, 2] = 1\n",
    "\n",
    "# -eps <= 1 * (x0 coefficient) + 1 * (x1 coefficient)\n",
    "constraint_lhs[1, 1] = -1\n",
    "constraint_lhs[1, 2] = -1\n",
    "\n",
    "# 1 * (x0 coefficient) <= 28\n",
    "constraint_lhs[2, 1 + n_features] = 1\n",
    "\n",
    "optimizer = ps.ConstrainedSR3(\n",
    "    constraint_rhs=constraint_rhs,\n",
    "    constraint_lhs=constraint_lhs,\n",
    "    inequality_constraints=True,\n",
    "    thresholder=\"l1\",\n",
    "    tol=1e-7,\n",
    "    threshold=10,\n",
    "    max_iter=10000\n",
    ")\n",
    "model = ps.SINDy(optimizer=optimizer, \n",
    "                 feature_library=library).fit(x_train, t=dt)\n",
    "model.print()\n",
    "print(optimizer.coef_[0, 1], optimizer.coef_[0, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SSR (greedy algorithm)\n",
    "Stepwise sparse regression (SSR) is a greedy algorithm which solves the problem (defaults to ridge regression) by iteratively truncating the smallest coefficient during the optimization. There are many ways one can decide to truncate terms. We implement two popular ways, truncating the smallest coefficient at each iteration, or chopping each coefficient, computing N - 1 models, and then choosing the model with the lowest residual error. See this [notebook](https://github.com/dynamicslab/pysindy/blob/master/examples/11_SSR_FROLS.ipynb) for examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssr_optimizer = ps.SSR(alpha=.05)\n",
    "\n",
    "model = ps.SINDy(optimizer=ssr_optimizer)\n",
    "model.fit(x_train, t=dt)\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The alpha parameter is the same here as in the STLSQ optimizer. It determines the amount of L2 regularization to use, so if alpha is nonzero, this is doing Ridge regression rather than least-squares regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssr_optimizer = ps.SSR(alpha=.05, criteria=\"model_residual\")\n",
    "model = ps.SINDy(optimizer=ssr_optimizer)\n",
    "model.fit(x_train, t=dt)\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The kappa parameter determines how sparse a solution is desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssr_optimizer = ps.SSR(alpha=.05, criteria=\"model_residual\", kappa=1e-3)\n",
    "model = ps.SINDy(optimizer=ssr_optimizer)\n",
    "model.fit(x_train, t=dt)\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FROLS (greedy algorithm)\n",
    "Forward Regression Orthogonal Least Squares (FROLS) is another greedy algorithm which solves the least-squares regression problem (actually default is to solve ridge regression) with $L_0$ norm by iteratively selecting the most correlated function in the library. At each step, the candidate functions are orthogonalized with respect to the already-selected functions. The selection criteria is the Error Reduction Ratio, i.e. the normalized increase in the explained output variance due to the addition of a given function to the basis. See this [notebook](https://github.com/dynamicslab/pysindy/blob/master/examples/11_SSR_FROLS.ipynb) for examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = ps.FROLS(alpha=.05)\n",
    "model = ps.SINDy(optimizer=optimizer)\n",
    "model.fit(x_train, t=dt)\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The kappa parameter determines how sparse a solution is desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = ps.FROLS(alpha=.05, kappa=1e-7)\n",
    "model = ps.SINDy(optimizer=optimizer)\n",
    "model.fit(x_train, t=dt)\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO\n",
    "In this example we use a third-party Lasso implementation (from scikit-learn) as the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T22:20:46.436242Z",
     "start_time": "2020-10-22T22:20:46.110756Z"
    }
   },
   "outputs": [],
   "source": [
    "lasso_optimizer = Lasso(alpha=2, max_iter=2000, fit_intercept=False)\n",
    "\n",
    "model = ps.SINDy(optimizer=lasso_optimizer)\n",
    "model.fit(x_train, t=dt)\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble methods\n",
    "One way to improve SINDy performance is to generate many models by sub-sampling the time series (ensemble) or sub-sampling the candidate library $\\mathbf{\\Theta}$ (library ensemble). The resulting models can then be synthesized by taking the average (bagging), taking the median (this is the recommended because it works well in practice), or some other post-processing. See this [notebook](https://github.com/dynamicslab/pysindy/blob/master/examples/13_ensembling.ipynb) for more examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default is to sample the entire time series with replacement, generating 10 models on roughly \n",
    "# 60% of the total data, with duplicates. \n",
    "\n",
    "# Custom feature names\n",
    "feature_names = ['x', 'y', 'z']\n",
    "\n",
    "ensemble_optimizer = ps.STLSQ(threshold=1e-3)\n",
    "model = ps.SINDy(optimizer=ensemble_optimizer, feature_names=feature_names)\n",
    "model.fit(x_train, t=dt, ensemble=True)\n",
    "ensemble_coefs = model.coef_list\n",
    "mean_ensemble = np.mean(ensemble_coefs, axis=0)\n",
    "std_ensemble = np.std(ensemble_coefs, axis=0)\n",
    "\n",
    "# Now we sub-sample the library. The default is to omit a single library term.\n",
    "library_ensemble_optimizer = ps.STLSQ(threshold=1e-3)\n",
    "model = ps.SINDy(optimizer=library_ensemble_optimizer, feature_names=feature_names)\n",
    "model.fit(x_train, t=dt, library_ensemble=True)\n",
    "library_ensemble_coefs = model.coef_list\n",
    "mean_library_ensemble = np.mean(library_ensemble_coefs, axis=0)\n",
    "std_library_ensemble = np.std(library_ensemble_coefs, axis=0)\n",
    "\n",
    "# Plot results\n",
    "xticknames = model.get_feature_names()\n",
    "for i in range(10):\n",
    "    xticknames[i] = '$' + xticknames[i] + '$'\n",
    "plt.figure(figsize=(10, 4))\n",
    "colors = ['b', 'r', 'k']\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('ensembling')\n",
    "for i in range(3):\n",
    "    plt.errorbar(range(10), mean_ensemble[i, :], yerr=std_ensemble[i, :], \n",
    "                 fmt='o', color=colors[i],\n",
    "                 label=r'Equation for $\\dot{' + feature_names[i] + r'}$')\n",
    "ax = plt.gca()\n",
    "plt.grid(True)\n",
    "ax.set_xticks(range(10))\n",
    "ax.set_xticklabels(xticknames, verticalalignment='top')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('library ensembling')\n",
    "for i in range(3):\n",
    "    plt.errorbar(range(10), mean_library_ensemble[i, :], yerr=std_library_ensemble[i, :], \n",
    "                 fmt='o', color=colors[i], \n",
    "                 label=r'Equation for $\\dot{' + feature_names[i] + r'}$')\n",
    "ax = plt.gca()\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "ax.set_xticks(range(10))\n",
    "ax.set_xticklabels(xticknames, verticalalignment='top');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differentiation options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pass in pre-computed derivatives\n",
    "Rather than using one of PySINDy's built-in differentiators, you can compute numerical derivatives using a method of your choice then pass them directly to the `fit` method. This option also enables you to use derivative data obtained directly from experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T22:20:46.478998Z",
     "start_time": "2020-10-22T22:20:46.441454Z"
    }
   },
   "outputs": [],
   "source": [
    "x_dot_precomputed = ps.FiniteDifference()._differentiate(x_train, t_train)\n",
    "    \n",
    "model = ps.SINDy()\n",
    "model.fit(x_train, t=t_train, x_dot=x_dot_precomputed)\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop end points from finite difference computation\n",
    "Many methods of numerical differentiation exhibit poor performance near the endpoints of the data. The `FiniteDifference` and `SmoothedFiniteDifference` methods allow one to easily drop the endpoints for improved accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T22:20:46.537504Z",
     "start_time": "2020-10-22T22:20:46.488114Z"
    }
   },
   "outputs": [],
   "source": [
    "fd_drop_endpoints = ps.FiniteDifference(drop_endpoints=True)\n",
    "    \n",
    "model = ps.SINDy(differentiation_method=fd_drop_endpoints)\n",
    "model.fit(x_train, t=t_train)\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differentiation along specific array axis\n",
    "For partial differential equations (PDEs), you may have spatiotemporal data in a multi-dimensional array. For this case, the `FiniteDifference` method allows one to only differential along a specific axis, so one can easily differentiate in a specific spatial direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "\n",
    "# Load the data stored in a matlab .mat file\n",
    "kdV = loadmat('data/kdv.mat')\n",
    "t = np.ravel(kdV['t'])\n",
    "X = np.ravel(kdV['x'])\n",
    "x = np.real(kdV['usol'])\n",
    "dt_kdv = t[1] - t[0]\n",
    "\n",
    "# Plot x and x_dot\n",
    "plt.figure()\n",
    "plt.pcolormesh(t, X, x)\n",
    "plt.xlabel('t', fontsize=16)\n",
    "plt.ylabel('X', fontsize=16)\n",
    "plt.title(r'$u(x, t)$', fontsize=16)\n",
    "plt.figure()\n",
    "x_dot = ps.FiniteDifference(axis=1)._differentiate(x, t=dt_kdv)\n",
    "\n",
    "plt.pcolormesh(t, X, x_dot)\n",
    "plt.xlabel('t', fontsize=16)\n",
    "plt.ylabel('x', fontsize=16)\n",
    "plt.title(r'$\\dot{u}(x, t)$', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoothed finite difference\n",
    "This method, designed for noisy data, applies a smoother (the default is `scipy.signal.savgol_filter`) before performing differentiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T22:20:46.598683Z",
     "start_time": "2020-10-22T22:20:46.540521Z"
    }
   },
   "outputs": [],
   "source": [
    "smoothed_fd = ps.SmoothedFiniteDifference()\n",
    "    \n",
    "model = ps.SINDy(differentiation_method=smoothed_fd)\n",
    "model.fit(x_train, t=t_train)\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More differentiation options\n",
    "PySINDy is compatible with any of the differentiation methods from the [derivative](https://pypi.org/project/derivative/) package. They are explored in detail in [this notebook](https://github.com/dynamicslab/pysindy/blob/master/examples/5_differentiation.ipynb).\n",
    "\n",
    "PySINDy defines a `SINDyDerivative` class for interfacing with `derivative` methods. To use a differentiation method provided by `derivative`, simply pass into `SINDyDerivative` the keyword arguments you would give the [dxdt](https://derivative.readthedocs.io/en/latest/api.html#derivative.differentiation.dxdt) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T22:20:46.930345Z",
     "start_time": "2020-10-22T22:20:46.606596Z"
    }
   },
   "outputs": [],
   "source": [
    "spline_derivative = ps.SINDyDerivative(kind=\"spline\", s=1e-2)\n",
    "\n",
    "model = ps.SINDy(differentiation_method=spline_derivative)\n",
    "model.fit(x_train, t=t_train)\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T22:20:46.952076Z",
     "start_time": "2020-10-22T22:20:46.932461Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_names = ['x', 'y', 'z']\n",
    "model = ps.SINDy(feature_names=feature_names)\n",
    "model.fit(x_train, t=dt)\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom left-hand side when printing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T22:20:46.987955Z",
     "start_time": "2020-10-22T22:20:46.954105Z"
    }
   },
   "outputs": [],
   "source": [
    "model = ps.SINDy()\n",
    "model.fit(x_train, t=dt)\n",
    "model.print(lhs=['dx0/dt', 'dx1/dt', 'dx2/dt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customize polynomial library\n",
    "Omit interaction terms between variables, such as $x_0 x_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T22:20:47.030687Z",
     "start_time": "2020-10-22T22:20:46.989999Z"
    }
   },
   "outputs": [],
   "source": [
    "poly_library = ps.PolynomialLibrary(include_interaction=False)\n",
    "\n",
    "model = ps.SINDy(feature_library=poly_library,            \n",
    "                 optimizer=ps.STLSQ(threshold=0.5))\n",
    "model.fit(x_train, t=dt)\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourier library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T22:20:47.116505Z",
     "start_time": "2020-10-22T22:20:47.034412Z"
    }
   },
   "outputs": [],
   "source": [
    "fourier_library = ps.FourierLibrary(n_frequencies=3)\n",
    "\n",
    "model = ps.SINDy(feature_library=fourier_library, \n",
    "                 optimizer=ps.STLSQ(threshold=4))\n",
    "model.fit(x_train, t=dt)\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully custom library\n",
    "The `CustomLibrary` class gives you the option to pass in function names to improve the readability of the printed model. Each function \"name\" should itself be a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T22:20:47.168456Z",
     "start_time": "2020-10-22T22:20:47.119321Z"
    }
   },
   "outputs": [],
   "source": [
    "library_functions = [\n",
    "    lambda x : np.exp(x),\n",
    "    lambda x : 1. / x,\n",
    "    lambda x : x,\n",
    "    lambda x,y : np.sin(x + y)\n",
    "]\n",
    "library_function_names = [\n",
    "    lambda x : 'exp(' + x + ')',\n",
    "    lambda x : '1/' + x,\n",
    "    lambda x : x,\n",
    "    lambda x,y : 'sin(' + x + ',' + y + ')'\n",
    "]\n",
    "custom_library = ps.CustomLibrary(\n",
    "    library_functions=library_functions, function_names=library_function_names\n",
    ")\n",
    "\n",
    "model = ps.SINDy(feature_library=custom_library)\n",
    "model.fit(x_train, t=dt, quiet=True)\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully custom library, default function names\n",
    "If no function names are given, default ones are given: `f0`, `f1`, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T22:20:47.230682Z",
     "start_time": "2020-10-22T22:20:47.171175Z"
    }
   },
   "outputs": [],
   "source": [
    "library_functions = [\n",
    "    lambda x : np.exp(x),\n",
    "    lambda x : 1./x,\n",
    "    lambda x : x,\n",
    "    lambda x,y : np.sin(x+y)\n",
    "]\n",
    "custom_library = ps.CustomLibrary(library_functions=library_functions)\n",
    "\n",
    "model = ps.SINDy(feature_library=custom_library)\n",
    "model.fit(x_train, t=dt, quiet=True)\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identity library\n",
    "The `IdentityLibrary` leaves input data untouched. It allows the flexibility for users to apply custom transformations to the input data before feeding it into a `SINDy` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T22:20:47.261567Z",
     "start_time": "2020-10-22T22:20:47.233639Z"
    }
   },
   "outputs": [],
   "source": [
    "identity_library = ps.IdentityLibrary()\n",
    "\n",
    "model = ps.SINDy(feature_library=identity_library)\n",
    "model.fit(x_train, t=dt)\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate two libraries\n",
    "Two or more libraries can be combined via the `+` operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T22:20:47.334576Z",
     "start_time": "2020-10-22T22:20:47.264641Z"
    }
   },
   "outputs": [],
   "source": [
    "identity_library = ps.IdentityLibrary()\n",
    "fourier_library = ps.FourierLibrary()\n",
    "combined_library = identity_library + fourier_library\n",
    "\n",
    "model = ps.SINDy(feature_library=combined_library,\n",
    "                 feature_names=feature_names)\n",
    "model.fit(x_train, t=dt)\n",
    "model.print()\n",
    "model.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor two libraries together\n",
    "Two or more libraries can be tensored together via the `*` operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identity_library = ps.PolynomialLibrary(include_bias=False)\n",
    "fourier_library = ps.FourierLibrary()\n",
    "combined_library = identity_library * fourier_library\n",
    "\n",
    "model = ps.SINDy(feature_library=combined_library,\n",
    "                 feature_names=feature_names)\n",
    "model.fit(x_train, t=dt)\n",
    "# model.print()  # prints out long and unobvious model\n",
    "print(\"Feature names:\\n\", model.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the model prediction is quite bad of course \n",
    "# because the library has mostly useless terms\n",
    "x_dot_test_predicted = model.predict(x_test)  \n",
    "\n",
    "# Compute derivatives with a finite difference method, for comparison\n",
    "x_dot_test_computed = model.differentiate(x_test, t=dt)\n",
    "\n",
    "fig, axs = plt.subplots(x_test.shape[1], 1, sharex=True, figsize=(7, 9))\n",
    "for i in range(x_test.shape[1]):\n",
    "    axs[i].plot(t_test, x_dot_test_computed[:, i],\n",
    "                'k', label='numerical derivative')\n",
    "    axs[i].plot(t_test, x_dot_test_predicted[:, i],\n",
    "                'r--', label='model prediction')\n",
    "    axs[i].legend()\n",
    "    axs[i].set(xlabel='t', ylabel='$\\dot x_{}$'.format(i))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalized library\n",
    "\n",
    "Create the most general and flexible possible library by combining and tensoring as many libraries as you want, and you can even specify which input variables to use to generate each library! A much more advanced example is shown further below for PDEs.\n",
    "One can specify:\n",
    "<br>\n",
    "1. N different libraries to add together\n",
    "2. A list of inputs to use for each library. For two libraries with four inputs this would look like inputs_per_library = [[0, 1, 2, 3], [0, 1, 2, 3]] and to avoid using the first two input variables in the second library, you would change it to something like inputs_per_library = [[0, 1, 2, 3], [2, 2, 2, 3]], since duplicates are thrown out and [2, 2, 2, 3] will reduce to [2, 3]. \n",
    "        \n",
    "3. A list of libraries to tensor together and add to the overall library. For four libraries, we could make three tensor libraries by using tensor_array = [[1, 0, 1, 1], [1, 1, 1, 1], [0, 0, 1, 1]]. The first sub-array takes the tensor product of libraries 0, 2, 3, the second takes the tensor product of all of them, and the last takes the tensor product of the libraries 2 and 3. This is a silly example since the [1, 1, 1, 1] tensor product already contains all the possible terms. <br>\n",
    "<br>\n",
    "Note that using this is a more advanced feature, but with the benefit that it allows any SINDy library you want. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize two libraries\n",
    "poly_library = ps.PolynomialLibrary(include_bias=False)\n",
    "fourier_library = ps.FourierLibrary()\n",
    "\n",
    "# Initialize the default inputs, i.e. each library\n",
    "# uses all the input variables\n",
    "inputs_temp = np.tile([0, 1, 2], 2)\n",
    "inputs_per_library = np.reshape(inputs_temp, (2, 3))\n",
    "\n",
    "# Don't use the x0 input for generating the Fourier library\n",
    "inputs_per_library[1, 0] = 1\n",
    "\n",
    "# Tensor all the polynomial and Fourier library terms together\n",
    "tensor_array = [[1, 1]]\n",
    "\n",
    "# Initialize this generalized library, all the work hidden from the user!\n",
    "generalized_library = ps.GeneralizedLibrary([poly_library, fourier_library], \n",
    "                                            tensor_array=tensor_array,\n",
    "                                            inputs_per_library=inputs_per_library)\n",
    "\n",
    "# Fit the model and print the library feature names to check success\n",
    "model = ps.SINDy(feature_library=generalized_library, \n",
    "                 feature_names=feature_names)\n",
    "model.fit(x_train, t=dt)\n",
    "model.print()\n",
    "print(\"Feature names:\\n\", model.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SINDy with control (SINDYc)\n",
    "SINDy models with control inputs can also be learned. Here we learn a Lorenz control model:\n",
    "$$ \\dot{x} = \\sigma (y - x) + u_0$$\n",
    "$$ \\dot{y} = x(\\rho - z) - y $$\n",
    "$$ \\dot{z} = x y - \\beta z - u_1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T22:20:47.495234Z",
     "start_time": "2020-10-22T22:20:47.367116Z"
    }
   },
   "outputs": [],
   "source": [
    "# Control input\n",
    "def u_fun(t):\n",
    "    return np.column_stack([np.sin(2 * t), t ** 2])\n",
    "\n",
    "# Generate measurement data\n",
    "dt = .002\n",
    "\n",
    "t_train = np.arange(0, 10, dt)\n",
    "t_train_span = (t_train[0], t_train[-1])\n",
    "x0_train = [-8, 8, 27]\n",
    "x_train = solve_ivp(lorenz_control, t_train_span, x0_train, \n",
    "                    t_eval=t_train, args=(u_fun,), **integrator_keywords).y.T\n",
    "u_train = u_fun(t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T22:20:47.527323Z",
     "start_time": "2020-10-22T22:20:47.497165Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate and fit the SINDYc model\n",
    "model = ps.SINDy()\n",
    "model.fit(x_train, u=u_train, t=dt)\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess results on a test trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T22:20:47.700551Z",
     "start_time": "2020-10-22T22:20:47.530536Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evolve the Lorenz equations in time using a different initial condition\n",
    "t_test = np.arange(0, 15, dt)\n",
    "t_test_span = (t_test[0], t_test[-1])\n",
    "u_test = u_fun(t_test)\n",
    "x0_test = np.array([8, 7, 15])\n",
    "x_test = solve_ivp(lorenz_control, t_test_span, x0_test, \n",
    "                   t_eval=t_test, args=(u_fun,), **integrator_keywords).y.T\n",
    "u_test = u_fun(t_test)\n",
    "\n",
    "# Compare SINDy-predicted derivatives with finite difference derivatives\n",
    "print('Model score: %f' % model.score(x_test, u=u_test, t=dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict derivatives with learned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T22:20:48.459184Z",
     "start_time": "2020-10-22T22:20:47.703317Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict derivatives using the learned model\n",
    "x_dot_test_predicted = model.predict(x_test, u=u_test)  \n",
    "\n",
    "# Compute derivatives with a finite difference method, for comparison\n",
    "x_dot_test_computed = model.differentiate(x_test, t=dt)\n",
    "\n",
    "fig, axs = plt.subplots(x_test.shape[1], 1, sharex=True, figsize=(7, 9))\n",
    "for i in range(x_test.shape[1]):\n",
    "    axs[i].plot(t_test, x_dot_test_computed[:, i],\n",
    "                'k', label='numerical derivative')\n",
    "    axs[i].plot(t_test, x_dot_test_predicted[:, i],\n",
    "                'r--', label='model prediction')\n",
    "    axs[i].legend()\n",
    "    axs[i].set(xlabel='t', ylabel='$\\dot x_{}$'.format(i))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate forward in time (control input function known)\n",
    "When working with control inputs `SINDy.simulate` requires a *function* to be passed in for the control inputs, `u`, because the default integrator used in `SINDy.simulate` uses adaptive time-stepping. We show what to do in the case when you do not know the functional form for the control inputs in the example following this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T22:20:51.769799Z",
     "start_time": "2020-10-22T22:20:48.460707Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evolve the new initial condition in time with the SINDy model\n",
    "x_test_sim = model.simulate(x0_test, t_test, u=u_fun)\n",
    "\n",
    "fig, axs = plt.subplots(x_test.shape[1], 1, sharex=True, figsize=(7, 9))\n",
    "for i in range(x_test.shape[1]):\n",
    "    axs[i].plot(t_test, x_test[:, i], 'k', label='true simulation')\n",
    "    axs[i].plot(t_test, x_test_sim[:, i], 'r--', label='model simulation')\n",
    "    axs[i].legend()\n",
    "    axs[i].set(xlabel='t', ylabel='$x_{}$'.format(i))\n",
    "\n",
    "fig = plt.figure(figsize=(10, 4.5))\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "ax1.plot(x_test[:, 0], x_test[:, 1], x_test[:, 2], 'k')\n",
    "ax1.set(xlabel='$x_0$', ylabel='$x_1$',\n",
    "        zlabel='$x_2$', title='true simulation')\n",
    "\n",
    "ax2 = fig.add_subplot(122, projection='3d')\n",
    "ax2.plot(x_test_sim[:, 0], x_test_sim[:, 1], x_test_sim[:, 2], 'r--')\n",
    "ax2.set(xlabel='$x_0$', ylabel='$x_1$',\n",
    "        zlabel='$x_2$', title='model simulation')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate forward in time (unknown control input function)\n",
    "If you only have a vector of control input values at the times in `t_test` and do not know the functional form for `u`, the `simulate` function will internally form an interpolating function based on the vector of control inputs. As a consequence of this interpolation procedure, `simulate` will not give a state estimate for the last time point in `t_test`. This is because the default integrator, `scipy.integrate.solve_ivp` (with LSODA as the default solver), is adaptive and sometimes attempts to evaluate the interpolant outside the domain of interpolation, causing an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T22:20:51.775131Z",
     "start_time": "2020-10-22T22:20:51.772119Z"
    }
   },
   "outputs": [],
   "source": [
    "u_test = u_fun(t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T22:20:55.799799Z",
     "start_time": "2020-10-22T22:20:51.776599Z"
    }
   },
   "outputs": [],
   "source": [
    "x_test_sim = model.simulate(x0_test, t_test, u=u_test)\n",
    "\n",
    "# Note that the output is one example short of the length of t_test\n",
    "print('Length of t_test:', len(t_test))\n",
    "print('Length of simulation:', len(x_test_sim))\n",
    "\n",
    "fig, axs = plt.subplots(x_test.shape[1], 1, sharex=True, figsize=(12, 4))\n",
    "for i in range(x_test.shape[1]):\n",
    "    axs[i].plot(t_test[:-1], x_test[:-1, i], 'k', label='true simulation')\n",
    "    axs[i].plot(t_test[:-1], x_test_sim[:, i], 'r--', label='model simulation')\n",
    "    axs[i].set(xlabel='t', ylabel='$x_{}$'.format(i))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implicit ODEs \n",
    "How would we use SINDy to solve an implicit ODE? In other words, now the LHS can depend on x and x_dot, \n",
    "$$\\dot{\\mathbf{x}} = \\mathbf{f}(\\mathbf{x}, \\dot{\\mathbf{x}})$$\n",
    "\n",
    "\n",
    "In order to deal with this, we need a library $\\Theta(\\mathbf{x}, \\dot{\\mathbf{x}})$. SINDy parallel implicit (SINDy-PI) is geared to solve these problems. It solves the optimization problem,\n",
    "$$argmin_\\mathbf{\\Xi} (\\|\\Theta(\\mathbf{X}, \\dot{\\mathbf{X}}) - \\Theta(\\mathbf{X}, \\dot{\\mathbf{X}})\\mathbf{\\Xi}\\| + \\lambda \\|\\mathbf{\\Xi}\\|_1)$$\n",
    "such that diag$(\\mathbf{\\Xi}) = 0$. So for every candidate library term it generates a different model. With N state variables, we need to choose N of the equations to solve for the system evolution. See the [SINDy-PI notebook](https://github.com/dynamicslab/pysindy/blob/master/examples/9_sindypi_with_sympy.ipynb) for more details. \n",
    "\n",
    "Here we illustrate successful identification of the 1D Michelson-Menten enzyme model\n",
    "$$\\dot{x} = 0.6 - \\frac{1.5 x}{0.3 + x}.$$\n",
    "Or, equivalently\n",
    "$$\\dot{x} = 0.6 - 3 x - \\frac{10}{3} x\\dot{x}.$$\n",
    "\n",
    "Note that some of the model fits fail. This is usually because the LHS term being fitted is a poor match to the data, but this error can also be caused by CVXPY not liking the parameters passed to the solver.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters\n",
    "r = 1\n",
    "dt = 0.001\n",
    "T = 4\n",
    "t = np.arange(0, T + dt, dt)\n",
    "t_span = (t[0], t[-1])\n",
    "x0_train = [0.55]\n",
    "x_train = solve_ivp(enzyme, t_span, x0_train, \n",
    "                    t_eval=t, **integrator_keywords).y.T\n",
    "\n",
    "# Initialize custom SINDy library so that we can have \n",
    "# x_dot inside it. \n",
    "x_library_functions = [\n",
    "    lambda x: x,\n",
    "    lambda x, y: x * y,\n",
    "    lambda x: x ** 2,\n",
    "    lambda x, y, z: x * y * z,\n",
    "    lambda x, y: x * y ** 2,\n",
    "    lambda x: x ** 3,\n",
    "    lambda x, y, z, w: x * y * z * w,\n",
    "    lambda x, y, z: x * y * z ** 2,\n",
    "    lambda x, y: x * y ** 3,\n",
    "    lambda x: x ** 4,\n",
    "]\n",
    "x_dot_library_functions = [lambda x: x]\n",
    "\n",
    "# library function names includes both the x_library_functions \n",
    "# and x_dot_library_functions names\n",
    "library_function_names = [\n",
    "    lambda x: x,\n",
    "    lambda x, y: x + y,\n",
    "    lambda x: x + x,\n",
    "    lambda x, y, z: x + y + z,\n",
    "    lambda x, y: x + y + y,\n",
    "    lambda x: x + x + x,\n",
    "    lambda x, y, z, w: x + y + z + w,\n",
    "    lambda x, y, z: x + y + z + z,\n",
    "    lambda x, y: x + y + y + y,\n",
    "    lambda x: x + x + x + x,\n",
    "    lambda x: x,\n",
    "]\n",
    "\n",
    "# Need to pass time base to the library so can build the x_dot library from x\n",
    "sindy_library = ps.SINDyPILibrary(\n",
    "    library_functions=x_library_functions,\n",
    "    x_dot_library_functions=x_dot_library_functions,\n",
    "    t=t[1:-1],\n",
    "    function_names=library_function_names,\n",
    "    include_bias=True,\n",
    ")\n",
    "\n",
    "# Use the SINDy-PI optimizer, which relies on CVXPY.\n",
    "# Note that if LHS of the equation fits the data poorly,\n",
    "# CVXPY often returns failure.\n",
    "sindy_opt = ps.SINDyPI(\n",
    "    threshold=1e-6,\n",
    "    tol=1e-8,\n",
    "    thresholder=\"l1\",\n",
    "    max_iter=20000,\n",
    ")\n",
    "model = ps.SINDy(\n",
    "    optimizer=sindy_opt,\n",
    "    feature_library=sindy_library,\n",
    "    differentiation_method=ps.FiniteDifference(drop_endpoints=True),\n",
    ")\n",
    "model.fit(x_train, t=t)\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDEFIND Feature Overview\n",
    "PySINDy now supports SINDy for PDE identification (PDE-FIND) (Rudy, Samuel H., Steven L. Brunton, Joshua L. Proctor, and J. Nathan Kutz. \"Data-driven discovery of partial differential equations.\" Science Advances 3, no. 4 (2017): e1602614.). We illustrate a basic example on Burgers' equation:\n",
    "$$u_t = -uu_x + 0.1u_{xx}$$\n",
    "\n",
    "Note that for noisy PDE data, the most robust method is to use the weak form of PDEFIND (see below)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "\n",
    "# Load data\n",
    "data = loadmat(\"data/burgers.mat\")\n",
    "t = np.ravel(data[\"t\"])\n",
    "x = np.ravel(data[\"x\"])\n",
    "u = np.real(data[\"usol\"])\n",
    "dt = t[1] - t[0]\n",
    "dx = x[1] - x[0]\n",
    "u_dot = ps.FiniteDifference(axis=-1)._differentiate(u, t=dt)\n",
    "\n",
    "# Plot the spatiotemporal data\n",
    "plt.figure()\n",
    "plt.imshow(u, aspect=\"auto\")\n",
    "plt.colorbar()\n",
    "plt.figure()\n",
    "plt.imshow(u_dot, aspect=\"auto\")\n",
    "plt.colorbar()\n",
    "u = np.reshape(u, (len(x), len(t), 1))\n",
    "\n",
    "# Define quadratic library with up to third order derivatives \n",
    "# on a uniform spatial grid\n",
    "library_functions = [lambda x: x, lambda x: x * x]\n",
    "library_function_names = [lambda x: x, lambda x: x + x]\n",
    "pde_lib = ps.PDELibrary(\n",
    "    library_functions=library_functions,\n",
    "    function_names=library_function_names,\n",
    "    derivative_order=3,\n",
    "    spatial_grid=x,\n",
    "    is_uniform=True,\n",
    ")\n",
    "\n",
    "optimizer = ps.STLSQ(threshold=0.1, alpha=1e-5, normalize_columns=True)\n",
    "model = ps.SINDy(feature_library=pde_lib, optimizer=optimizer)\n",
    "\n",
    "# Note that the dimensions of u are reshaped internally,\n",
    "# according to the dimensions in spatial_grid\n",
    "model.fit(u, t=dt)\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weak formulation system identification improves robustness to noise.\n",
    "PySINDy also supports weak form PDE identification following Reinbold et al. (2019)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same library but using the weak formulation\n",
    "library_functions = [lambda x: x, lambda x: x * x]\n",
    "library_function_names = [lambda x: x, lambda x: x + x]\n",
    "X, T = np.meshgrid(x, t)\n",
    "XT = np.array([X, T]).T\n",
    "pde_lib = ps.WeakPDELibrary(\n",
    "    library_functions=library_functions,\n",
    "    function_names=library_function_names,\n",
    "    derivative_order=3,\n",
    "    spatiotemporal_grid=XT,\n",
    "    is_uniform=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = ps.STLSQ(threshold=0.01, alpha=1e-5, normalize_columns=True)\n",
    "model = ps.SINDy(feature_library=pde_lib, optimizer=optimizer)\n",
    "\n",
    "# Note that reshaping u is done internally\n",
    "model.fit(u, t=dt)\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GeneralizedLibrary\n",
    "The `GeneralizedLibrary` is meant for identifying ODEs/PDEs the depend on the spatial and/or temporal coordinates and/or nonlinear functions of derivative terms.\n",
    "\n",
    "Often, especially for PDEs, there is some explicit spatiotemporal dependence such as through an external potential. For instance, a well known PDE is the Poisson equation for the electric potential in 2D:\n",
    "$$ (\\partial_{xx} + \\partial_{yy})\\phi(x, y) = \\rho(x,y).$$\n",
    "\n",
    "\n",
    "**Note that all other SINDy libraries implemented in PySINDy only allow for functions of $\\phi(x, y)$ on the RHS of the SINDy equation.** This method allows for functions of the spatial and temporal coordinates like $\\rho(x, y)$, as well as anything else you can imagine.\n",
    "\n",
    "Let's suppose we have a distribution like the following\n",
    "$$ \\rho(x, y) = x^2 + y^2$$\n",
    "We can actually directly input $(\\partial_{xx} + \\partial_{yy})\\phi(x, y)$ as \"x_dot\" in the SINDy fit, functionally replacing the normal left-hand-side (LHS) of the SINDy equation. Then we can build a candidate library of terms to discover the correct charge density matching this data.\n",
    "\n",
    "In the following, we will build three different libraries, each using their own subset of inputs, tensor a subset of them together, and fit a model. This is total overkill for this problem but hopefully is illustrative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the spatial grid\n",
    "nx = 50\n",
    "Lx = 1\n",
    "ny = 100\n",
    "Ly = 1\n",
    "x = np.linspace(0, Lx, nx)\n",
    "dx = x[1] - x[0]\n",
    "y = np.linspace(0, Ly, ny)\n",
    "dy = y[1] - y[0]\n",
    "X, Y = np.meshgrid(x, y, indexing=\"ij\")\n",
    "\n",
    "# Define rho\n",
    "rho = X ** 2 + Y ** 2\n",
    "plt.figure(figsize=(20, 3))\n",
    "plt.subplot(1, 5, 1)\n",
    "plt.imshow(rho, aspect=\"auto\", origin=\"lower\")\n",
    "plt.title(r\"$\\rho(x, y)$\")\n",
    "plt.colorbar()\n",
    "\n",
    "# Generate the PDE data for phi by fourier transforms \n",
    "# since this is homogenous PDE\n",
    "# and we assume periodic boundary conditions\n",
    "nx2 = int(nx / 2)\n",
    "ny2 = int(ny / 2)\n",
    "# Define Fourier wavevectors (kx, ky)\n",
    "kx = (2 * np.pi / Lx) * np.hstack(\n",
    "    (np.linspace(0, nx2 - 1, nx2), np.linspace(-nx2, -1, nx2))\n",
    ")\n",
    "ky = (2 * np.pi / Ly) * np.hstack(\n",
    "    (np.linspace(0, ny2 - 1, ny2), np.linspace(-ny2, -1, ny2))\n",
    ")\n",
    "\n",
    "# Get 2D mesh in (kx, ky)\n",
    "KX, KY = np.meshgrid(kx, ky, indexing=\"ij\")\n",
    "K2 = KX ** 2 + KY ** 2\n",
    "K2[0, 0] = 1e-5\n",
    "\n",
    "# Generate phi data by solving the PDE and plot results\n",
    "phi = np.real(np.fft.ifft2(-np.fft.fft2(rho) / K2))\n",
    "plt.subplot(1, 5, 2)\n",
    "plt.imshow(phi, aspect=\"auto\", origin=\"lower\")\n",
    "plt.title(r\"$\\phi(x, y)$\")\n",
    "plt.colorbar()\n",
    "\n",
    "# Make del^2 phi and plot various quantities\n",
    "phi_xx = ps.FiniteDifference(d=2, axis=0)._differentiate(phi, dx)\n",
    "phi_yy = ps.FiniteDifference(d=2, axis=1)._differentiate(phi, dy)\n",
    "plt.subplot(1, 5, 3)\n",
    "plt.imshow(phi_xx, aspect=\"auto\", origin=\"lower\")\n",
    "plt.title(r\"$\\phi_{xx}(x, y)$\")\n",
    "plt.subplot(1, 5, 4)\n",
    "plt.imshow(phi_yy, aspect=\"auto\", origin=\"lower\")\n",
    "plt.title(r\"$\\phi_{yy}(x, y)$\")\n",
    "plt.subplot(1, 5, 5)\n",
    "plt.imshow(\n",
    "    phi_xx + phi_yy + abs(np.min(phi_xx + phi_yy)),\n",
    "    aspect=\"auto\",\n",
    "    origin=\"lower\",\n",
    ")\n",
    "plt.title(r\"$\\phi_{xx}(x, y) + \\phi_{yy}(x, y)$\")\n",
    "plt.colorbar()\n",
    "\n",
    "# Define a PolynomialLibrary, FourierLibrary, and PDELibrary\n",
    "poly_library = ps.PolynomialLibrary(include_bias=False)\n",
    "fourier_library = ps.FourierLibrary()\n",
    "X_mesh, Y_mesh = np.meshgrid(x, y)\n",
    "pde_library = ps.PDELibrary(\n",
    "    derivative_order=1, \n",
    "    spatial_grid=np.asarray([X_mesh, Y_mesh]).T\n",
    ")\n",
    "\n",
    "# Inputs are going to be all the variables [phi, X, Y].\n",
    "# Remember we can use a subset of these input variables to generate each library\n",
    "data = np.transpose(np.asarray([phi, X, Y]), [1, 2, 0])\n",
    "\n",
    "# The 'x_dot' terms will be [phi_xx, X, Y]\n",
    "# Remember these are the things that are being fit in the SINDy regression\n",
    "Laplacian_phi = phi_xx + phi_yy + abs(np.min(phi_xx + phi_yy))\n",
    "data_dot = np.transpose(np.asarray([Laplacian_phi, X, Y]), [1, 2, 0])\n",
    "\n",
    "# Tensor polynomial library with the PDE library\n",
    "tensor_array = [[1, 0, 1]]\n",
    "\n",
    "# Remove X and Y from PDE library terms because why would we take these derivatives\n",
    "inputs_temp = np.tile([0, 1, 2], 3)\n",
    "inputs_per_library = np.reshape(inputs_temp, (3, 3))\n",
    "inputs_per_library[2, 1] = 0\n",
    "inputs_per_library[2, 2] = 0\n",
    "\n",
    "# Fit a generalized library of 3 feature libraries + 1 internally \n",
    "# generated tensored library and only use the input variable phi \n",
    "# for the PDELibrary. Note that this holds true both for the \n",
    "# individual PDELibrary and any tensored libraries constructed from it.\n",
    "generalized_library = ps.GeneralizedLibrary(\n",
    "    [poly_library, fourier_library, pde_library],\n",
    "    tensor_array=tensor_array,\n",
    "    inputs_per_library=inputs_per_library,\n",
    ")\n",
    "optimizer = ps.STLSQ(threshold=8, normalize_columns=True)\n",
    "model = ps.SINDy(feature_library=generalized_library, optimizer=optimizer)\n",
    "model.fit(data, x_dot=data_dot)\n",
    "\n",
    "# Note scale of phi is large so some coefficients >> 1\n",
    "# --> would want to rescale phi with eps_0 for a harder problem\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get prediction of rho and plot results\n",
    "rho_pred = model.predict(data)\n",
    "plt.figure(figsize=(16, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(r'True $\\rho$')\n",
    "plt.imshow(rho, aspect='auto', origin='lower')\n",
    "plt.colorbar()\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(r'Predicted $\\rho_p$')\n",
    "plt.imshow(rho_pred[:, :, 0], aspect='auto', origin='lower')\n",
    "plt.colorbar()\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(r'Residual errors $\\rho - \\rho_p$')\n",
    "plt.imshow(rho - rho_pred[:, :, 0], aspect='auto', origin='lower')\n",
    "plt.colorbar()\n",
    "print(\"Feature names:\\n\", model.get_feature_names())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "296.475px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
